---
share: true
---

# Problem

- Transformer在NLP领域大获成功，但是在机器视觉领域还没有纯Transformer的方法；

# Approach

ViT 采用了传统 Transformer 模型的架构，它将图像分解为一系列小块（patch），将这些块线性嵌入为序列，然后输入到标准的 Transformer 结构中。

# Architecture

## Partition
- Reshaping the image (HxW×C) into a sequence of flattened 2D patches；
- Patch的解析度是PxP，则每个patch的像素向量$x_P$的维度是$N$x$P^2C$，其中$N=HW/P^2$；

## Embedding
- Flatten the patches $x_P$
- Map it to $D$ dimensions with a trainable linear projection；
- Postional Encoding：1-D Position embeddings are added to the patch embeddings to retain positional information；

## Transformer Encoder
- 标准Transformer，由MultiHeadAttention + LayerNorm + MLP（中间使用GeLU）组成一层，然后循环多遍；

## Head
- MLP for classification；

# Ref
- AN IMAGE IS WORTH 16X16 WORDS TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE






